{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import pymongo\n",
    "from flask import Flask, render_template, redirect\n",
    "from flask_pymongo import PyMongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_browser(): \n",
    "# Use splinter to start up a Chrome driver\n",
    "    executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "    browser = Browser('chrome', **executable_path, headless=False)\n",
    "init_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'news_title': 'NASA Prepares for Moon and Mars With New Addition to Its Deep Space Network',\n",
       " 'news_p': 'Robotic spacecraft will be able to communicate with the dish using radio waves and lasers.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_nasa_news():\n",
    "    news = {}\n",
    "    url =  'https://mars.nasa.gov/news'\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'html.parser')\n",
    "    #result = soup.find('li', class_='slide')\n",
    "    result = soup.find('div', class_='slide')\n",
    "    # Extract the most recent news' title and content\n",
    "    #news_title = result.find('li', class_=\"content_title\").find('a').text\n",
    "    news_title = result.find('div', class_=\"content_title\").find('a').text.strip()\n",
    "    #news_p = result.find('li', class_=\"article_teaser_body\").text\n",
    "    news_p = result.a.text.strip()\n",
    "    news[\"news_title\"] = news_title\n",
    "    news[\"news_p\"] = news_p\n",
    "    return news\n",
    "scrape_nasa_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA16919_ip.jpg'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_featured_image():\n",
    "    url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "    base_url =\"https://www.jpl.nasa.gov\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    article = soup.find(\"article\")\n",
    "    \n",
    "    featured_img_url = base_url + article.a['data-fancybox-href']\n",
    "    return featured_img_url\n",
    "scrape_featured_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'InSight sol 442 (2020-02-23) low -94.1ºC (-137.3ºF) high -10.5ºC (13.0ºF)\\nwinds from the SSE at 6.2 m/s (13.8 mph) gusting to 21.1 m/s (47.3 mph)\\npressure at 6.30 hPapic.twitter.com/lfdFlvxVxe'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_latest_twitt():\n",
    "    url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    \n",
    "    mars_weather = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")[0].text\n",
    "    return mars_weather\n",
    "scrape_latest_twitt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>value</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Equatorial Diameter:</th>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>Polar Diameter:</th>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg (0.11 Earths)</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Distance:</th>\\n      <td>227,943,824 km (1.38 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>Orbit Period:</th>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>Surface Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n    </tr>\\n    <tr>\\n      <th>First Record:</th>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>Recorded By:</th>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_mars_facts():\n",
    "    url = 'http://space-facts.com/mars/'\n",
    "    # Use Panda's `read_html` to parse the url\n",
    "    tables = pd.read_html(url)\n",
    "    df = tables[0]\n",
    "    df.columns = ['description', 'value']\n",
    "    df.set_index('description', inplace=True)\n",
    "    return df.to_html()\n",
    "scrape_mars_facts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cerberus Hemisphere Enhanced',\n",
       " 'Schiaparelli Hemisphere Enhanced',\n",
       " 'Syrtis Major Hemisphere Enhanced',\n",
       " 'Valles Marineris Hemisphere Enhanced']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_hemispheres():\n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    response = requests.get(url)\n",
    "    soup = bs(response.text, 'lxml')\n",
    "    \n",
    "    hemispheres = []\n",
    "    results = soup.find_all(\"div\", class_=\"description\")\n",
    "    \n",
    "    for result in results:\n",
    "        hemispheres.append(result.h3.text)\n",
    "        \n",
    "    # hemispheres = ['Cerberus', 'Schiaparelli', 'Syrtis Major', 'Valles Marineris']\n",
    "    return hemispheres\n",
    "scrape_hemispheres()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_hemisphere_info():\n",
    "    hemispheres = scrape_hemispheres()\n",
    "    hemisphere_info = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'visit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-b9355fe9adb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhemisphere_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mscrape_hemisphere_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-b9355fe9adb2>\u001b[0m in \u001b[0;36mscrape_hemisphere_info\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbrowser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhemi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhemispheres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'visit'"
     ]
    }
   ],
   "source": [
    "def scrape_hemisphere_info():\n",
    "    hemispheres = scrape_hemispheres()\n",
    "    hemisphere_info = []\n",
    "    \n",
    "    \n",
    "    browser = init_browser()\n",
    "    \n",
    "    url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(url)\n",
    "    \n",
    "    for hemi in hemispheres:\n",
    "        #  Hemisphere\n",
    "        browser.click_link_by_partial_text(f'{hemi}')\n",
    "        \n",
    "        # create HTML object, Parse HTML with Beautiful Soup\n",
    "        html = browser.html\n",
    "        soup = bs(html, 'html.parser')\n",
    "        # Initialize the dict\n",
    "        hemi_dict = {}\n",
    "        # Scrape the incomplete URL\n",
    "        inc_url = soup.find('img', class_='wide-image')['src']\n",
    "        # Construct the complete URL\n",
    "        img_url = 'https://astrogeology.usgs.gov' + inc_url\n",
    "        # Store the data in a dictionary then add that dictionary to the tracking list\n",
    "        hemi_dict[\"title\"] = f'{hemi}'\n",
    "        hemi_dict[\"img_url\"] = img_url\n",
    "        hemisphere_info.append(hemi_dict)\n",
    "        \n",
    "        # Return to the original page\n",
    "        browser.click_link_by_partial_text('Back')\n",
    "        \n",
    "    browser.quit()\n",
    "    return hemisphere_info\n",
    "\n",
    "scrape_hemisphere_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape():\n",
    "    mars_facts = {}\n",
    "    mars_facts[\"news_title\"] = scrape_nasa_news()[\"news_title\"]\n",
    "    mars_facts[\"news_p\"] = scrape_nasa_news()[\"news_p\"]\n",
    "    mars_facts[\"featured_image_url\"] = scrape_featured_image()\n",
    "    mars_facts[\"mars_weather\"] = scrape_latest_twitt()\n",
    "    mars_facts[\"mars_facts_table\"] = scrape_mars_facts()\n",
    "    mars_facts[\"hemisphere_info\"] = scrape_hemisphere_info()\n",
    "    # Return the dictionary\n",
    "    return mars_facts\n",
    "scrape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
